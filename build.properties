# Drupal configuration
# --------------------

# The project name.
project.name = joinup

# The install profile to use.
website.profile.name = ${project.name}

# The site name.
website.site.name = Joinup

# The infrastructure stack.
infra.type = joinup

# SQL database settings.
drupal.db.name = db_name
drupal.db.user = db_user
drupal.db.password = db_pass
drupal.db.dsn = ${drupal.db.type}:host=${drupal.db.host};dbname=${drupal.db.name}

# SPARQL database settings.
sparql.host = localhost
sparql.port = 8890
sparql.dsn = localhost
sparql.user = dba
sparql.password = dba
sparql.namespace = Drupal\\Driver\\Database\\joinup_sparql

# Comma-separated list of demo users to create. The username and password will
# be taken from the role. A normal authenticated user with username and password
# 'user' will also be created.
drupal.demo.users = administrator, moderator


# Virtuoso
# --------

# The location of the Virtuoso binary. Preferably overwrite this locally with a
# absolute path for increased security.
virtuoso.binary = virtuoso-t

# The location of the database dump to use when restoring Virtuoso.
virtuoso.backup = ${exports.virtuoso.destination.folder}


# Paths
# -----

# Paths to executables.
git.bin = /usr/bin/git
isql.bin = /usr/bin/isql-vt
solr.bin = ${project.basedir}/vendor/bin/solr

# Files and directories inside the Drupal installation.
documentroot.path = web
website.drupal.dir = ${project.basedir}/${documentroot.path}
website.services.yml = ${website.settings.dir}/services.yml

# Composer related paths.
composer.json = ${project.basedir}/composer.json

# Temporary files.
tmp.dir = ${project.basedir}/tmp

# Exported configuration.
drupal.config.dir = ${project.basedir}/config/sync

# Drupal private files directory.
drupal.private_files.dir = ${project.basedir}/private


# Behat configuration
# -------------------

# Enable strict mode in Behat tests. Will only pass if all tests are explicitly
# passing.
behat.options.strict = false

# Set verbosity for Behat tests. 0 is completely silent, 1 is normal output, 2
# shows exception backtraces, 3 shows debugging information.
behat.options.verbosity = 2

# The location where to save screenshots that are taken whenever a test fails.
# If left empty no screenshots will be taken.
# behat.screenshots.local.dir = ${tmp.dir}/behat-screenshots
behat.screenshots.local.dir =

# The location on AWS S3 where to upload screenshots that are taken whenever a
# test fails. This is especially helpful for storing screenshots taken during
# test runs on continuous integration services. The S3 bucket, key and secret
# to use are configured in the 'AWS S3' section below.
# If either this or any of the 'AWS S3' properties are left empty no screenshots
# will be uploaded to S3.
# behat.screenshots.s3.dir = behat-screenshots
behat.screenshots.s3.dir =


# PHP CodeSniffer configuration
# -----------------------------

# Whether or not to run a coding standards check before doing a git push. Note
# that this will abort the push if the coding standards check fails.
phpcs.prepush.enable = 1

# Paths to check, delimited by semicolons.
phpcs.files = ${website.modules.dir};${website.profiles.dir};${website.themes.dir};${behat.dir}/src

# Paths to ignore, delimited by semicolons.
phpcs.ignore = ${website.modules.dir}/contrib;${website.themes.dir}/joinup/prototype;${website.modules.dir}/custom/joinup_communities/tallinn/lib


# PHPUnit configuration
# ---------------------

# Comma-separated list of directories containing tests to execute. These are
# relative to the Drupal root.
phpunit.directories = ./modules/custom,./profiles,./themes/custom

# Comma-separated list of test files to execute. These are relative to the
# Drupal root.
phpunit.files =

# The database URL for testing SPARQL queries.
phpunit.sparql_url = sparql://${sparql.host}:${sparql.port}/


# Apache Solr configuration
# -------------------------

# Apache Solr version to use.
solr.version = 7.7.1

# Filename of the download.
solr.tarball.filename = solr-${solr.version}.tgz

# Download URL.
solr.download.url = http://archive.apache.org/dist/lucene/solr/${solr.version}/${solr.tarball.filename}

# Installation path.
solr.vendor.dir = ${project.basedir}/vendor/apache
solr.dir = ${solr.vendor.dir}/solr-${solr.version}

# Search API configuration path.
solr.config.dir = ${website.modules.dir}/contrib/search_api_solr/solr-conf/6.x

# Solr core for published content.
solr.core.published.name = drupal_published
solr.core.published.scheme = http
solr.core.published.host = localhost
solr.core.published.port = 8983
solr.core.published.path = /solr
solr.core.published.url = ${solr.core.published.scheme}://${solr.core.published.host}:${solr.core.published.port}${solr.core.published.path}
solr.core.published.dir = ${solr.dir}/server/solr/${solr.core.published.name}

# Solr core for unpublished content.
solr.core.unpublished.name = drupal_unpublished
solr.core.unpublished.scheme = http
solr.core.unpublished.host = localhost
solr.core.unpublished.port = 8983
solr.core.unpublished.path = /solr
solr.core.unpublished.url = ${solr.core.unpublished.scheme}://${solr.core.unpublished.host}:${solr.core.unpublished.port}${solr.core.unpublished.path}
solr.core.unpublished.dir = ${solr.dir}/server/solr/${solr.core.unpublished.name}


# Development options
# -------------------

# Development modules to enable.
drupal.modules.dev = admin_toolbar cas_mock_server config_devel config_update devel field_ui filecache joinup_cas_mock_server views_ui

# Modules to enable for doing user acceptance testing.
drupal.modules.uat = demo_users

# Redirect outgoing e-mail to disk. This prevents e-mail from being
# accidentally sent out on development machines. The mails can be found in the
# folder temporary://devel-mails. This requires the devel module to be enabled.
drupal.redirect.email = yes


# AWS SDK
# -------
aws.profile = default
aws.region = eu-west-1


# AWS CodeDeploy
# --------------
deploy.serviceRole = arn:aws:iam::918396081007:role/CodeDeploy


# AWS S3
# ------

# The S3 bucket that contains the database dumps.
exports.s3.bucket = joinup2

# The key and secret to access the bucket. If left empty the credentials will
# be retrieved from the environment. For documentation on how to set the
# credentials on the environment, see \Aws\Credentials\CredentialProvider.
exports.s3.key =
exports.s3.secret =

# The paths to the database dumps. Note that the Virtuoso dump consists of
# multiple files so this is pointing to the folder containing the files.
# Folder names should end in slashes.
# The following two variables also need to be set. Each, is the direct link to the
# corresponding dump.
# exports.virtuoso.source = http://example.com/virtuoso.tar.gz
# exports.sql.source = http://example.com/sql.sql.gz
# exports.solr.filename = solr.tar.gz
# exports.solr.source = http://example.com/${export.solr.filename}
exports.virtuoso.destination.folder = ${tmp.dir}/dump-virtuoso/
exports.sql.destination = ${tmp.dir}/dump.sql.gz
exports.solr.destination.folder = ${tmp.dir}/solr

asda.username =
asda.password =


# Packer configuration
# --------------------
packer.path = /usr/bin/env packer
packer.args =
application.name = ${project.name}


# SCSSPHP compiler configuration
# ------------------------------

# The SCSSPHP  executable.
scssphp.bin = ${project.basedir}/vendor/bin/pscss

# The path to the SCSS file to compile.
scssphp.input.file = ${website.themes.dir}/joinup/prototype/scss/app.scss

# The directory where the compiled CSS file should be placed.
scssphp.css.output.dir = ${website.themes.dir}/joinup/css

# The filename of the compiled CSS file.
scssphp.css.output.file = ${scssphp.css.output.dir}/style.min.css

# The code style. Can be compact, compressed, crunched, expanded, or nested.
scssphp.style = compressed


# Analytics configuration
# -----------------------

# Website ID. This can be seen in the Matomo UI, at Administration > Websites >
# Manage.
matomo.website_id = 1

# Optional HTTP URL to the Matomo server. Only intended for development
# environments.
matomo.url.http =

# Optional HTTPS URL to the Matomo server. Intended for production environments.
matomo.url.https =

# Authentication token. This can be retrieved from the Matomo web interface at
# Administration > Platform > API > User authentication.
matomo.token = 0123456789abcdef0123456789abcdef

# The site ID to use with Webtools Analytics.
webtools_analytics.site_id = ${matomo.website_id}

# The site path to use with Webtools Analytics. This defaults to the user
# acceptance environment so that we will not accidentally pollute our analytics
# data when running Joinup on an environment that doesn't properly override
# these properties.
webtools_analytics.site_path = joinup.uat.fpfis.tech.ec.europa.eu

# The Webtools Analytics server instance to use. This defaults to the test
# environment so that we will not accidentally pollute our analytics data when
# running Joinup on an environment that doesn't properly override these
# properties.
webtools_analytics.instance = testing


# Redis configuration
# -------------------

# The IP address of the Redis host.
# Uncomment this line to enable the Redis cache.
# redis.host = 127.0.0.1


# Stage file proxy settings
# -------------------------

# The origin of the files without the trailing '/'. Leave empty to disable the functionality.
stage_file_proxy.origin = http://example.com

# If true, then the request will get a 301 redirection to the remote server
# rather than downloading the file.
stage_file_proxy.hotlink = TRUE

# Config read-only
# ----------------

# Set this value to FALSE in `build.properties.local` to have config_readonly
# disabled on the development environment.
config_readonly.enabled = TRUE


# EU Login
# --------

# These are the settings for the EU Login authentication service. It is only
# needed to configure this when you need to work on user authentication, and
# want to try out the login form redirects from the Drupal login form to the
# authentication service and back. Be warned that this service is contained in a
# docker image which is very large and resource hungry.
#
# Note also that the some parts of the image rely on having kernel support for
# `vsyscall` which has been removed from the Linux kernel in version 3.2. If you
# are unable to start the docker container it is possible you are running a
# newer kernel. To debug this issue, try the following command:
#
# $ cd ./tmp/eulogin
# $ docker-compose up
#
# If this exits with error 139 your kernel does not support `vsyscall`. You can
# enable an emulated version of this deprecated feature by passing the
# `vsyscall=emulated` kernel parameter on boot.
#
# For more info on this issue see the following links:
# - https://lore.kernel.org/patchwork/patch/920530/
# - https://docs.docker.com/samples/library/centos/#a-note-about-vsyscall

# eCAS Mock Server Docker registry credentials.
# Set the user and password values in your build.properties.local file.
# eulogin.ecas_mock.docker.registry.user =
# eulogin.ecas_mock.docker.registry.password =
eulogin.ecas_mock.docker.registry.server = https://registry.fpfis.tech.ec.europa.eu

# eCAS Mock Server image.
eulogin.ecas_mock.docker.image = registry.fpfis.tech.ec.europa.eu/ecas-mock-server:4.6.0

# eCAS Mock Server config fixtures dir.
eulogin.ecas_mock.config_fixtures.dir = ${project.basedir}/web/modules/custom/eulogin/tests/fixtures/ecas-mock-server-config


# Drupal Test Traits (DTT) settings.
# ----------------------------------

dtt.base_url = ${drupal.base_url}
dtt.api_url = ${behat.webdriver_url}
dtt.mink_driver_args = ['chrome', null, 'http://localhost:4444/wd/hub']


# Sleep intervals. This is used by the 'sleep' target which is useful in certain
# circumstances. For instance in CI when we'll need a time for the services to
# get up and be ready to be used.
# -----------------------------------------------------------------------------

sleep.hours = 0
sleep.minutes = 0
sleep.seconds = 0
sleep.milliseconds = 0
